{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from Pre_processing import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_curl = pd.read_csv(r'coords-curls (1).csv')\r\n",
    "df_sqt = pd.read_csv(r'coords-squads (1).csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_c = Pre_process(df_curl)\r\n",
    "df_s = Pre_process(df_sqt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_total = pd.concat([df_c, df_s], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_total.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid.no</th>\n",
       "      <th>obs.no</th>\n",
       "      <th>frame.no</th>\n",
       "      <th>pose</th>\n",
       "      <th>y0</th>\n",
       "      <th>z0</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>...</th>\n",
       "      <th>y28</th>\n",
       "      <th>z28</th>\n",
       "      <th>y29</th>\n",
       "      <th>z29</th>\n",
       "      <th>y30</th>\n",
       "      <th>z30</th>\n",
       "      <th>y31</th>\n",
       "      <th>z31</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>curls</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>-0.81768</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>-0.850829</td>\n",
       "      <td>0.054339</td>\n",
       "      <td>-0.848987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064071</td>\n",
       "      <td>0.515654</td>\n",
       "      <td>0.042985</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>-0.038118</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.060827</td>\n",
       "      <td>0.705341</td>\n",
       "      <td>-0.062449</td>\n",
       "      <td>0.640884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>curls</td>\n",
       "      <td>0.018654</td>\n",
       "      <td>-0.81768</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>-0.850829</td>\n",
       "      <td>0.054339</td>\n",
       "      <td>-0.848987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064071</td>\n",
       "      <td>0.515654</td>\n",
       "      <td>0.042985</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>-0.038118</td>\n",
       "      <td>0.524862</td>\n",
       "      <td>0.060827</td>\n",
       "      <td>0.705341</td>\n",
       "      <td>-0.062449</td>\n",
       "      <td>0.640884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vid.no  obs.no  frame.no   pose        y0       z0        y1        z1  \\\n",
       "0       1       1         1  curls  0.018654 -0.81768  0.041363 -0.850829   \n",
       "1       1       1         2  curls  0.018654 -0.81768  0.041363 -0.850829   \n",
       "\n",
       "         y2        z2  ...       y28       z28       y29       z29       y30  \\\n",
       "0  0.054339 -0.848987  ... -0.064071  0.515654  0.042985  0.604052 -0.038118   \n",
       "1  0.054339 -0.848987  ... -0.064071  0.515654  0.042985  0.604052 -0.038118   \n",
       "\n",
       "        z30       y31       z31       y32       z32  \n",
       "0  0.524862  0.060827  0.705341 -0.062449  0.640884  \n",
       "1  0.524862  0.060827  0.705341 -0.062449  0.640884  \n",
       "\n",
       "[2 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_total = df_total.replace('curls', 1)\r\n",
    "df_total = df_total.replace('squats', 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "train = df_total.iloc[:,4:].to_numpy()\r\n",
    "Xtrain = np.reshape(train,(-1,50,66)).astype(np.double)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "y1 = df_c.groupby(['vid.no','obs.no']).max()['pose']\r\n",
    "y2 = df_s.groupby(['vid.no','obs.no']).max()['pose']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "ytrain = pd.concat([y1, y2], axis=0).replace('squats', 0).replace('curls',1).values.reshape((-1,1)).astype(np.double)\r\n",
    "ytrain.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(487, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(Xtrain,ytrain, test_size = 0.25, random_state = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "x_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(365, 50, 66)"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(365, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "class LSTM(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\r\n",
    "        super(LSTM,self).__init__()\r\n",
    "        self.hidden_dim = hidden_dim\r\n",
    "        self.output_dim = output_dim\r\n",
    "        self.lstm = torch.nn.LSTM(input_dim,hidden_dim,layer_num,batch_first=True)\r\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\r\n",
    "        self.bn = nn.BatchNorm1d(50)\r\n",
    "        \r\n",
    "    def forward(self,inputs):\r\n",
    "        x = self.bn(inputs)\r\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\r\n",
    "        out = self.fc(lstm_out[:,-1,:])\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "n_hidden = 128\r\n",
    "n_joints = 33*2\r\n",
    "n_categories = 2\r\n",
    "n_layer = 3\r\n",
    "rnn = LSTM(n_joints,n_hidden,n_categories,n_layer)\r\n",
    "rnn.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(66, 128, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "LABELS = ['squats', 'curls']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "def categoryFromOutput(output):\r\n",
    "    top_n, top_i = output.topk(1)\r\n",
    "    category_i = top_i[0].item()\r\n",
    "    return LABELS[category_i], category_i"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "tensor_X_test = torch.from_numpy(x_test).double()\r\n",
    "print('test_data_size:',tensor_X_test.size())\r\n",
    "tensor_y_test = torch.from_numpy(y_test).double()\r\n",
    "print('test_label_size:',tensor_y_test.size())\r\n",
    "n_data_size_test = tensor_X_test.size()[0]\r\n",
    "print('n_data_size_test:',n_data_size_test)\r\n",
    "\r\n",
    "tensor_X_train = torch.from_numpy(x_train).double()\r\n",
    "print('train_data_size:',tensor_X_train.size())\r\n",
    "tensor_y_train = torch.from_numpy(y_train).double()\r\n",
    "print('train_label_size:',tensor_y_train.size())\r\n",
    "n_data_size_train = tensor_X_train.size()[0]\r\n",
    "print('n_data_size_train:',n_data_size_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_data_size: torch.Size([122, 50, 66])\n",
      "test_label_size: torch.Size([122, 1])\n",
      "n_data_size_test: 122\n",
      "train_data_size: torch.Size([365, 50, 66])\n",
      "train_label_size: torch.Size([365, 1])\n",
      "n_data_size_train: 365\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "import random\r\n",
    "def randomTrainingExampleBatch(batch_size,flag,num=-1):\r\n",
    "    if flag == 'train':\r\n",
    "        X = tensor_X_train\r\n",
    "        y = tensor_y_train\r\n",
    "        data_size = n_data_size_train\r\n",
    "    elif flag == 'test':\r\n",
    "        X = tensor_X_test\r\n",
    "        y = tensor_y_test\r\n",
    "        data_size = n_data_size_test\r\n",
    "    if num == -1:\r\n",
    "        ran_num = random.randint(0,data_size-batch_size)\r\n",
    "    else:\r\n",
    "        ran_num = num\r\n",
    "    pose_sequence_tensor = X[ran_num:(ran_num+batch_size)]\r\n",
    "    pose_sequence_tensor = pose_sequence_tensor\r\n",
    "    category_tensor = y[ran_num:ran_num+batch_size,:]\r\n",
    "    return category_tensor.long(),pose_sequence_tensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import torch.optim as optim\r\n",
    "import time\r\n",
    "import math\r\n",
    "\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "learning_rate = 0.0005\r\n",
    "optimizer = optim.SGD(rnn.parameters(),lr=learning_rate,momentum=0.9)\r\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.1)\r\n",
    "\r\n",
    "n_iters = 100000\r\n",
    "#n_iters = 60000\r\n",
    "print_every = 1000\r\n",
    "plot_every = 1000\r\n",
    "batch_size = 128\r\n",
    "\r\n",
    "# Keep track of losses for plotting\r\n",
    "current_loss = 0\r\n",
    "all_losses = []\r\n",
    "\r\n",
    "def timeSince(since):\r\n",
    "    now = time.time()\r\n",
    "    s = now - since\r\n",
    "    m = math.floor(s / 60)\r\n",
    "    s -= m * 60\r\n",
    "    return '%dm %ds' % (m, s)\r\n",
    "\r\n",
    "start = time.time()\r\n",
    "\r\n",
    "for iter in range(1, n_iters + 1):\r\n",
    "   \r\n",
    "    category_tensor, input_sequence = randomTrainingExampleBatch(batch_size,'train')\r\n",
    "    input_sequence = input_sequence.to(device)\r\n",
    "    category_tensor = category_tensor.to(device)\r\n",
    "    category_tensor = torch.squeeze(category_tensor)\r\n",
    "    \r\n",
    "    optimizer.zero_grad()\r\n",
    "    \r\n",
    "    output = rnn(input_sequence.float())\r\n",
    "    loss = criterion(output, category_tensor)\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step() \r\n",
    "\r\n",
    "    current_loss += loss.item()\r\n",
    "    \r\n",
    "    category = LABELS[int(category_tensor[0])]\r\n",
    "\r\n",
    "    # Print iter number, loss, name and guess\r\n",
    "    if iter % print_every == 0:\r\n",
    "        guess, guess_i = categoryFromOutput(output)\r\n",
    "        correct = 'âœ“' if guess == category else 'âœ— (%s)' % category\r\n",
    "        print('%d %d%% (%s) %.4f  / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, guess, correct))\r\n",
    "        \r\n",
    "    # Add current loss avg to list of losses\r\n",
    "    if iter % plot_every == 0:\r\n",
    "        all_losses.append(current_loss / plot_every)\r\n",
    "        current_loss = 0"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-36bf9a9ce068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-445015f4d2a8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    680\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(rnn.state_dict(),'lstm_6_bn.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "507157c702ed78002e2ebc825a47493be3352b03df2ad897d91f69b927688cb6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}